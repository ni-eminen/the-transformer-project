# The Transformer Project
This project consists of three parts:
1. The Perceptron
	- Just a perceptron, a single neuron capable of binary classification. This gives me a basis in understanding how feedforward neural networks work, weights, activation functions, loss functions, bias terms, backpropagation all implemented from scratch.
2. A multi-layer feedforward neural network (FNN) implemented from scratch. This gives me an idea of how larger neural networks work, how backpropagation is implmented in a larger network.
3. A Transformer. This part will be a minimal implementation of a transformer from scratch based on Attention Is All You Need.
